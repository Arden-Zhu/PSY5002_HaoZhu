{
  "hash": "c41e3cc2fddbbed59c1ec6108d0c8036",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Paper\"\nauthor: \"Hao Zhu\"\ndate: \"2025-03-15\"\ncategories: [scripts]\n---\n\n\n\n(Title)\n\n# Introduction\n\nHuman learning hinges on the ability to recognize and interpret predictive cues in the environment. Classic work in associative learning has shown that when two or more cues consistently appear together, their interactions can be competitive—where a dominant cue “blocks” another from acquiring associative strength—or facilitative, in which cues mutually boost each other’s predictive value. These phenomena play a fundamental role not only in understanding how people learn cause-effect relationships but also in broader psychological processes such as selective attention, cognitive inference, and clinical outcomes related to anxiety and stress. In the dissertation by Alhazmi (2022), a series of experiments explored the interplay between these different styles of cue interaction—particularly examining why some individuals tend toward facilitative (or “noncompetitive”) learning while others exhibit more canonical patterns of cue competition. The present paper focuses on Experiment 4 of that work, in which I conducted a detailed data analysis to investigate individual differences in cue interaction style (competitive vs. facilitative) and whether their styles are related to anxiety, depression, and stress measures. By leveraging advanced statistical techniques acquired in my independent research course, I re-examined the data to (add details later).\n\nThis introductory section provides an overview of the theoretical basis for cue interaction, including both classical associative models and more contemporary accounts that incorporate higher-order cognitive processes.\n\nTheoretical accounts of cue interaction have historically emphasized how cues compete for associative strength, a process often referred to as “cue competition.” Early associative models (e.g., Bush & Mosteller, 1951, 1955) proposed that the predictive value of any given cue depends solely on its individual correlation with the outcome. This view was challenged by the influential Rescorla-Wagner model (Rescorla & Wagner, 1972), which introduced the concept of a summed prediction error. According to this model, cues presented in compound share a limited pool of associative strength; a cue that is already a strong predictor of an outcome will “block” new cues from acquiring substantial associative strength (Kamin, 1968; Rescorla & Wagner, 1972). Later theories, particularly attentional models (Mackintosh, 1975; Pearce & Hall, 1980), posited that competition stems not just from summed prediction errors but also from changes in the amount of attention allocated to each cue.\n\nHowever, accumulating evidence suggests that cues can also facilitate one another—rather than compete—under certain circumstances (Bouton et al., 1987; Durlach & Rescorla, 1980). Such “cue facilitation” occurs when the presence of a well-established cue enhances the predictive value of a novel cue (Batsell Jr & Batson, 1999). Models addressing both competition and facilitation often incorporate within-compound associations—that is, direct links formed between cues presented together. In the Sometimes-Competing Retrieval (SOCR) model (Stout & Miller, 2007), these within-compound associations may either suppress or augment responding, depending on a “switching operator” that governs whether indirect cue activation will interfere with or bolster responding. Similarly, Pineño’s (2007) extension of the Rescorla-Wagner model assumes that a cue’s novelty moderates how strongly it draws on within-compound associations for its response—leading sometimes to competition, sometimes to facilitation. These dual-process models thus capture both the classic competitive phenomena and the growing body of evidence for cooperative, or facilitative, interactions among cues.\n\nIn addition to these associative mechanisms, propositional and higher-order reasoning can also influence cue interactions. According to propositional accounts, human learners form cognitive inferences about causal relationships, rather than simply accumulating associative strength through trial-by-trial error signals (Mitchell et al., 2009). Thus, learners may explicitly reason that “if Cue A by itself predicts the outcome, and Cue A together with Cue X produces no change in the outcome, then Cue X is not causally relevant,” leading to blocking-like effects (Cheng & Novick, 1990; De Houwer & Beckers, 2003). Higher-order cognition may similarly generate facilitative effects if learners reason that a known predictor could boost the effectiveness of other cues present in the same compound. These propositional processes need not replace traditional associative mechanisms; indeed, both conscious inference and lower-level associative learning may jointly shape how cues compete or facilitate one another under varying task conditions (Mitchell et al., 2009).\n\nAnother theoretical perspective on cue interaction revolves around **within-compound associations**, which are direct links formed between cues that are presented simultaneously. Rather than focusing exclusively on how each cue associates with an outcome, this view emphasizes that cues can become associated with each other—sometimes resulting in one cue retrieving the memory of its partner, which in turn activates the representation of the shared outcome (Melchers et al., 2004; Miller & Matzel, 1988). This mechanism can explain why, for instance, reinforcing one element of a compound (A) in a later stage may retrospectively weaken or enhance responses to the other (X), even when X is not explicitly retrained—an effect not easily handled by standard, purely competitive models. Recent formulations, such as Pineño’s (2007) model or the Sometimes-Competing Retrieval (SOCR) model (Stout & Miller, 2007), specifically integrate within-compound associations to account for both **competitive** interactions (when indirect retrieval suppresses responding) and **facilitative** interactions (when indirect retrieval augments responding). By focusing on how cues become interconnected, these approaches help clarify why certain learners show noncompetitive or “excessive” associative patterns that can, in clinical populations, manifest as overgeneralized fear or heightened sensitivity to redundant cues.\n\nTaken together, these perspectives underscore how cue interaction can manifest in both competitive and facilitative patterns, shaped by propositional reasoning as well as by within-compound associations. In the fourth experiment of Alhazmi’s (2022) dissertation, these themes converge in a paradigm specifically designed to capture variability in cue interaction styles under carefully controlled conditions. The next sections detail how I reanalyzed the dataset from this experiment, leveraging advanced statistical methods to explore (1) whether individual shows differences in cue competition or facilitation, and (2) how these differences might correlate with measures of anxiety, depression, and stress.\n\n**Description of the Fourth Experiment**\n\nExperiment 4 was developed to determine how within-compound associations might tilt cue interaction toward competitive or facilitative patterns, and whether these individual tendencies align with varying levels of anxiety, depression, and stress. The experiment utilized a two-stage training procedure—initial training followed by compound trials—culminating in a reversal manipulation that differed between two groups. What follows is a more detailed account of the procedure:\n\n**Participants and Design.**\n\nOver 400 adults were recruited online (via Prolific) and randomly assigned to one of two groups: Control (no outcome reversal) or Experimental (outcome reversal).\n\nIn both groups, each participant was exposed to two cues (A and B) initially reinforced with coins or bomb outcomes, respectively, so that A reliably predicted a positive outcome (coins) while B reliably predicted a negative outcome (bomb).\n\nStage 1 (Initial Training).\n\nCues A and B were each presented multiple times (e.g., eight trials per cue). Consistent with the design, Cue A was always followed by the coin outcome, while Cue B was always followed by the bomb outcome. This stage established a baseline expectation that A = coins and B = bomb.\n\nStage 2 (Compound Training).\n\nBoth groups next received extended training over several blocks (e.g., seven blocks). These blocks included the original cues (A→coins, B→bomb) plus newly introduced compound cues:  AW (A paired with a novel cue W), 75% resulting in coins and 25% in bombs.\n\nBZ (B paired with a novel cue Z), 25% resulting in coins and 75% in bombs.\n\nAX (A with novel cue X) and BY (B with novel cue Y), each reinforced 50% of the time with coins.\n\nThese compound trials tested how novel cues (W, X, Y, Z) might “inherit” more or less coin or bomb expectancy from their better-established partners (A or B). Of particular interest were X and Y, the target cues, since they were paired with opposite outcomes on half the trials and thus could trend toward coins or bombs depending on how participants integrated the companion cue’s history.\n\nStage 3 (Reversal Manipulation).\n\nAt this point, the Experimental group received a reversal of outcomes for Cues A and B (i.e., A became bomb, B became coins), while the Control group continued with the same contingencies (A = coins, B = bomb).\n\nThe logic behind this manipulation was to identify whether people who relied on strong within-compound associations (especially for cues X or Y) would update the predictive value of those target cues more drastically than those who did not depend on within-compound links.\n\nStage 4 (Final Probe Trials).\n\nBoth groups completed additional probe trials in which Cues A, B, X, and Y were tested individually without explicit feedback, to assess how much the earlier reversal or continued training influenced each cue’s perceived outcome.\n\n**Dependent Variables**\n\n1.  **Distance.** A key behavioral measure was how close participants positioned themselves (or their avatar) to the anticipated outcome location on each trial. By standing near the center when they predicted coins (to maximize reward) or retreating toward the edge if they expected a bomb (to avoid penalty), participants generated a continuous “distance” metric that captured their outcome expectations in real time. Shorter distances indicated a higher belief in receiving coins, whereas larger distances pointed to a strong expectation of bombs.\n\n2.  **Ratings.** In addition to the distance measure, participants periodically provided explicit numeric ratings of how likely they believed it was that the cue in question predicted coins (as opposed to bombs). After each trial—or at defined “probe” trials—participants were shown a rating scale (for instance, 0 to  10) and indicated how confident they were that the current cue would lead to a coin outcome. These ratings supplemented the distance data by revealing learners’ conscious expectations about each cue’s predictive value.\n\n**Anxiety, Depression, and Stress Measures.**\n\nAfter the learning task, participants completed the DASS questionnaire (Lovibond, 1995), yielding subscales for depression, anxiety, and stress. These scores were later correlated with each participant’s “cue interaction index” (the degree to which X vs. Y showed competition or facilitation), testing the hypothesis that attenuated competition (i.e., facilitation) might be linked to higher clinical-risk traits such as anxiety or chronic stress.\n\n# Data Analysis\n\n## Data Preparation\n\nLoad data and packages\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif(!require('tidyverse')) {\n  # install.packages('tidyverse')\n  library(tidyverse)\n}\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: tidyverse\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n\n\n:::\n\n```{.r .cell-code}\nif(!require('tidyr')) {\n  #install.packages('tidyr'); \n  library(tidyr)\n}\nif(!require('ggplot2')) {\n  #install.packages('ggplot2'); \n  library(ggplot2)\n}\nif(!require('gridExtra')) {\n  #install.packages('gridExtra'); \n  library(gridExtra)\n}\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: gridExtra\n\nAttaching package: 'gridExtra'\n\nThe following object is masked from 'package:dplyr':\n\n    combine\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(corrplot)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\ncorrplot 0.94 loaded\n```\n\n\n:::\n:::\n\n\n\nImport Data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_game <- read_csv('../../data/exp4-raw.csv', show_col_types=FALSE)\ndf_quest <- read_csv('../../data/exp4-raw-quest.csv', show_col_types=FALSE)\ndf_attention <- read_csv('../../data/exp4-attention.csv', show_col_types=FALSE)\n```\n:::\n\n\n\nWe used many filters to exclude bad data - Here is the data from the platform itself. Either people who did not complete the whole thing, or they were too fast for their data to be meaningful, or they skipped all the ratings/probes, all kinds of reasons.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbads <- c('594fa525f61b8e00016af178', '5a90460d1eda41000135f918',\n       '5de301515253b03390043d12', '5e87ade2da382941f3f1a621',\n       '5ed377271691ea000c548cb0', '5f3e8506cb479c0a96cf4aac',\n       '5f8f95862a4ed820d9b071ac', '60b671ce563975c4907b9c04')\ndf_game = df_game %>% filter(!subjectID %in% bads)\n```\n:::\n\n\n\nWe also have participants complete a survey called DAAS in which they answer a couple of questions and then we extract their depression, anxiety and stress scores. As you can see, we have these dimensions mapped to questions and in the following code we just add up all the scores in each dimension.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define the question categories\ndepression <- c(3, 5, 10, 13, 16, 17, 21, 24, 26, 31, 34, 37, 38)\nanxiety <- c(2, 4, 7, 9, 15, 19, 20, 23, 25, 28, 30, 36, 40)\nstress <- c(1, 6, 8, 11, 12, 14, 18, 22, 27, 29, 32, 33, 35, 39)\n\n# Create column names for each category\ndepression_cols <- paste0('DASS_', depression)\nanxiety_cols <- paste0('DASS_', anxiety)\nstress_cols <- paste0('DASS_', stress)\n\n# Sum the columns for each category and add to df_quest\ndf_quest <- df_quest %>%\n  mutate(\n    depression = rowSums(select(., all_of(depression_cols)), na.rm = TRUE),\n    anxiety = rowSums(select(., all_of(anxiety_cols)), na.rm = TRUE),\n    stress = rowSums(select(., all_of(stress_cols)), na.rm = TRUE)\n  )\n\n# Drop columns that start with 'DASS'\ndf_quest <- df_quest %>%\n  select(-starts_with('DASS'))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# focus on probe data\ndf_prp_raw <- df_game %>% filter(outcome == 'probe')\n\n# check invalid ratings\ndf_prp_raw %>%\n  filter(probeAns<0 | probeAns>1) %>%\n  select(subjectID) %>%\n  distinct()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 0 × 1\n# ℹ 1 variable: subjectID <chr>\n```\n\n\n:::\n\n```{.r .cell-code}\n# we can use this to filter out those who have lots of missing ratings..\nmissing <- df_prp_raw %>% \n  group_by(subjectID) %>%\n  summarize(missing = mean(is.na(probeAns))) %>%\n  arrange(desc(missing))\n\nhead(missing)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 2\n  subjectID                missing\n  <chr>                      <dbl>\n1 5c8d12309d2bff0019b4054a  0.977 \n2 5c2fcd716ea6880001dc8e3d  0.932 \n3 5ce031fc7f65ee001a985a6b  0.932 \n4 5f3ec6221b5af3158bc86acd  0.5   \n5 5fca97a4b105427256733533  0.159 \n6 5915e5c6405db80001f30ff1  0.0682\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# here we also have issues with invalid ratings and we want to know how many bad data out there\ninvalidRatings <- missing %>% filter(missing >= 0.5) %>% pull(subjectID)\ndf_prp_raw %>% \n  filter(subjectID %in% invalidRatings) %>% \n  group_by(group) %>%\n  summarize(n = n_distinct(subjectID))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  group            n\n  <chr>        <int>\n1 control          3\n2 experimental     1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# filter them out...\ndf_game <- df_game %>% filter(!subjectID %in% invalidRatings)\ndf_prp_raw <- df_game %>% filter(outcome == 'probe')\n\nn_distinct(df_prp_raw$subjectID)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 393\n```\n\n\n:::\n:::\n\n\n\nHow many participants in each group?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_prp_raw %>%\n  group_by(group) %>%\n  summarize(n = n_distinct(subjectID))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  group            n\n  <chr>        <int>\n1 control        203\n2 experimental   190\n```\n\n\n:::\n:::\n\n\n\n## Start of the analysis\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#df_trn_raw <- df_game %>% filter(outcome != 'probe')\ndf_prp_raw <- df_game %>% filter(outcome == 'probe')\n```\n:::\n\n\n\nWe want to use an average of pre reversal and post reversal. We select 6, 7,8 for pre-reversal baseline and 10,11,12 for post reversal. Note that we also have 6 but we skip it because participant see ratings for first time and they are figuring it out.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_prp_focus <- df_prp_raw %>%\n  filter(rep %in% c(6, 7, 8, 10, 11, 12)) %>%\n  mutate(rep = recode(rep, `6` = 'before', `7` = 'before', `8` = 'before', `10` = 'after', `11` = 'after', `12` = 'after')) \n\ndf_prp <- df_prp_focus %>%\n  group_by(subjectID, cue, rep) %>%\n  summarize(probeAns = mean(probeAns, na.rm = TRUE),\n            distance = mean(distance, na.rm = TRUE), .groups = 'drop')\n\nhead(df_prp)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 5\n  subjectID                cue   rep    probeAns distance\n  <chr>                    <chr> <chr>     <dbl>    <dbl>\n1 55acde7cfdf99b28fb8d7e44 A     after  1            84.3\n2 55acde7cfdf99b28fb8d7e44 A     before 0.998       119. \n3 55acde7cfdf99b28fb8d7e44 AW    before 0.0882      581  \n4 55acde7cfdf99b28fb8d7e44 AX    before 0.411       306  \n5 55acde7cfdf99b28fb8d7e44 B     after  0.000952    571  \n6 55acde7cfdf99b28fb8d7e44 B     before 0           589. \n```\n\n\n:::\n:::\n\n\n\n## Stimulus\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# shapes and sounds\n# symbol should be unique for each subject and cue\ndf_prp_focus %>%\n  filter( cue %in% c(\"X\", \"Y\")) %>%\n  group_by(subjectID, cue) %>%\n  summarise( ns = n_distinct(shape), nd = n_distinct(sound), .groups = \"drop\") %>%\n  filter( ns > 1 | nd > 1) \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 0 × 4\n# ℹ 4 variables: subjectID <chr>, cue <chr>, ns <int>, nd <int>\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_stimuls <- df_prp_focus %>%\n  filter( cue %in% c(\"X\", \"Y\")) %>%\n  group_by(subjectID, cue) %>%\n  summarise( shape = first(shape), sound = first(sound), .groups = \"drop\") %>%\n  mutate( stimulus_type = case_when(shape == 'empty' ~ 'sound', .default = 'shape'),\n          stimulus = case_when(stimulus_type == 'sound' ~ sound, .default = shape)) %>%\n  pivot_wider(names_from = cue, values_from = c(stimulus_type, stimulus), id_cols = subjectID, names_prefix = '') %>%\n  mutate( stimulus_type_X_Y = paste(stimulus_type_X, stimulus_type_Y, sep = \"_\"),\n          stimulus_X_Y = paste(stimulus_X, stimulus_Y, sep = \"_\"))\n```\n:::\n\n\n\n## Transform\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# some magic to pivot from long to wide (easier for analysis)\ndf_prp_ratings_wide <- df_prp %>%\n  pivot_wider(names_from = cue, values_from = probeAns, id_cols = c(subjectID, rep))\n\ndf_prp_distance_wide <- df_prp %>%\n  pivot_wider(names_from = cue, values_from = distance, id_cols = c(subjectID, rep))\n\ndf_prp_ratings_wide <- df_prp_ratings_wide %>%\n  pivot_wider(\n    names_from = rep,        \n    values_from = -c(subjectID, rep), \n    names_sep = \"_\"           \n  ) %>%\n  select(-c('AW_after', 'AX_after', 'BY_after', 'BZ_after', 'W_after', 'Z_after'))\n\ndf_prp_distance_wide <- df_prp_distance_wide %>%\n  pivot_wider(\n    names_from = rep,\n    values_from = -c(subjectID, rep),\n    names_sep = \"_\"      \n  ) %>%\n  select(-c('AW_after', 'AX_after', 'BY_after', 'BZ_after', 'W_after', 'Z_after'))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# merge the two dataframes\ndf_prp_both <- df_prp_ratings_wide %>%\n  left_join(df_prp_distance_wide, by = \"subjectID\", suffix = c('_rating', '_dist'))\n```\n:::\n\n\n\nWe merge because we can get all information now including group and scores...\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_prp_both <- df_prp_both %>%\n  left_join(df_quest, by = \"subjectID\") %>%\n  #left_join(df_attention, by = \"subjectID\") %>%\n  left_join(df_game %>% filter(outcome == 'probe') %>%\n              select(subjectID, group) %>%\n              distinct(), by = \"subjectID\") %>%\n  left_join(df_stimuls %>% \n              select(subjectID, stimulus_type_X_Y, stimulus_X_Y), by = \"subjectID\")\n```\n:::\n\n\n\nFilter out the participants who did not rating the stimuli in a meaningful way\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_prp_both <- df_prp_both %>% filter(A_before_rating > B_before_rating, \n                                      A_before_rating > AW_before_rating,\n                                      AW_before_rating < BZ_before_rating, \n                                      B_before_rating < BZ_before_rating,\n                                      )\n\ndf_prp_both <- df_prp_both %>% filter(W_before_rating < Z_before_rating)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_prp_both %>%\n  group_by(group) %>%\n  summarize(n = n_distinct(subjectID))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  group            n\n  <chr>        <int>\n1 control        172\n2 experimental   143\n```\n\n\n:::\n:::\n\n\n## Normalized Index\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nICI_Norm <- function(Y, X) (Y - X) / sqrt(Y^2 + X^2)\n\ndf_prp_both <- df_prp_both %>%\n  mutate(ICI_YX_rating_pre_norm = ICI_Norm(Y_before_rating, X_before_rating),\n         ICI_YX_dist_pre_norm = - ICI_Norm(Y_before_dist, X_before_dist),\n         ICI_YX_rating_post_norm = ICI_Norm(Y_after_rating, X_after_rating),\n         ICI_YX_dist_post_norm = - ICI_Norm(Y_after_dist, X_after_dist),\n         post_pre_Rating_norm = ICI_YX_rating_post_norm - ICI_YX_rating_pre_norm,\n         post_pre_Dist_norm = ICI_YX_dist_post_norm - ICI_YX_dist_pre_norm)\n\ndf_prp_both <- df_prp_both %>%\n  mutate(ICI_WZ_rating_pre_norm = ICI_Norm(W_before_rating, Z_before_rating),\n         ICI_WZ_dist_pre_norm = - ICI_Norm(W_before_dist, Z_before_dist))\n```\n:::\n\n\n\n### Distributions\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_distribution <- function(df, x, title) {\n  p <- ggplot(df, aes(x = !!sym(x))) +\n  geom_histogram(bins=10, fill = \"grey40\", color = \"white\") +\n  labs(title = title, x = \"Scores\", y = \"\") +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(size = 14, hjust = 0.5),\n    axis.title.x = element_text(size = 12),\n    axis.title.y = element_text(size = 12)\n  )\n  return(p)\n}\n\np1 <- plot_distribution(df_prp_both, \"ICI_YX_rating_pre_norm\", \"Pre-Rating ICI_YX\")\np2 <- plot_distribution(df_prp_both%>%filter(group == \"control\"), \"ICI_YX_rating_post_norm\", \"Post-Rating for Control\")\np3 <- plot_distribution(df_prp_both%>%filter(group == \"experimental\"), \"ICI_YX_rating_post_norm\", \"Post-Rating for Experiment\")\n\np4 <- plot_distribution(df_prp_both, \"ICI_YX_dist_pre_norm\", \"Pre-distance ICI_YX\")\np5 <- plot_distribution(df_prp_both%>%filter(group == \"control\"), \"ICI_YX_dist_post_norm\", \"Post-distance ICI_YX for Control\")\np6 <- plot_distribution(df_prp_both%>%filter(group == \"experimental\"), \"ICI_YX_dist_post_norm\", \"Post-distance ICI_YX for Experiment\")\n\ngrid.arrange(p1, p2, p3, p4, p5, p6, ncol = 3)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-19-1.png){width=1248}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- plot_distribution(df_prp_both, \"ICI_WZ_rating_pre_norm\", \"Pre-Rating ICI_WZ\")\n\np4 <- plot_distribution(df_prp_both, \"ICI_WZ_dist_pre_norm\", \"Pre-distance ICI_WZ\")\n\ngrid.arrange(p1, p4, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# First plot: Scatter plot of ICI_YX_rating_pre_norm vs ICI_WZ_rating_pre_norm\nggplot(df_prp_both, aes(x = ICI_YX_rating_pre_norm, y = ICI_WZ_rating_pre_norm)) +\n  geom_point() +\n  labs(title = \"Scatter plot of ICI_YX vs ICI_WZ Ratings\",\n       x = \"ICI_YX Rating\",\n       y = \"ICI_WZ Rating\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Second plot: Scatter plot of ICI_YX_dist_pre_norm vs ICI_WZ_dist_pre_norm\nggplot(df_prp_both, aes(x = ICI_YX_dist_pre_norm, y = ICI_WZ_dist_pre_norm)) +\n  geom_point() +\n  labs(title = \"Scatter plot of ICI_YX vs ICI_WZ Distances\",\n       x = \"ICI_YX Distance\",\n       y = \"ICI_WZ Distance\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-21-2.png){width=672}\n:::\n:::\n\n\n\nPlot accumulated probability distribution group by stimulus type\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_accumulated_density <- function(df, x, color, title) {\n  p <- ggplot(df, aes(x = !!sym(x), color = !!sym(color))) +\n    stat_ecdf(geom = \"step\", size = 1) +  \n    labs(title = title, x = \"Scores\", y = \"Cumulative Probability\") +\n    theme_minimal() +\n    theme(\n      plot.title = element_text(size = 14, hjust = 0.5),\n      axis.title.x = element_text(size = 12),\n      axis.title.y = element_text(size = 12)\n    )\n  return(p)\n}\n\nplot_density <- function(df, x, color, title) {\n  p <- ggplot(df, aes(x = !!sym(x), color = !!sym(color))) +\n    geom_density(aes(y = ..count..), fill = \"grey40\", alpha = 0.5) +\n    #stat_ecdf(geom = \"step\", size = 1) +  \n    labs(title = title, x = \"Scores\", y = \"Cumulative Probability\") +\n    theme_minimal() +\n    theme(\n      plot.title = element_text(size = 14, hjust = 0.5),\n      axis.title.x = element_text(size = 12),\n      axis.title.y = element_text(size = 12)\n    )\n  return(p)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- plot_density(df_prp_both, \"ICI_YX_rating_pre_norm\", \"stimulus_type_X_Y\", \"Density\\n of Pre-Rating\")\np2 <- plot_density(df_prp_both, \"ICI_YX_dist_pre_norm\", \"stimulus_type_X_Y\", \"Density \\n of Pre-Distance\")\n\ngrid.arrange(p1, p2, ncol=2)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(count)` instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-23-1.png){width=1248}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- plot_accumulated_density(df_prp_both, \"ICI_YX_rating_pre_norm\", \"stimulus_type_X_Y\", \"Cumulative Density\\n of Pre-Rating\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n\n\n:::\n\n```{.r .cell-code}\np2 <- plot_accumulated_density(df_prp_both, \"ICI_YX_dist_pre_norm\", \"stimulus_type_X_Y\", \"Cumulative Density \\n of Pre-Distance\")\n\ngrid.arrange(p1, p2, ncol=2)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-24-1.png){width=1248}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- plot_density(df_prp_both, \"ICI_YX_rating_pre_norm\", \"stimulus_X_Y\", \"Density of Pre-Rating\")\n\ngrid.arrange(p1, ncol=1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n\n```{.r .cell-code}\np1 <- plot_density(df_prp_both, \"ICI_YX_dist_pre_norm\", \"stimulus_X_Y\", \"Density of Pre-Distance\")\n\ngrid.arrange(p1, ncol=1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-25-2.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\np1 <- plot_accumulated_density(df_prp_both, \"ICI_YX_rating_pre_norm\", \"stimulus_X_Y\", \"Cumulative Density of Pre-Rating\")\n\ngrid.arrange(p1, ncol=1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n\n```{.r .cell-code}\np1 <- plot_accumulated_density(df_prp_both, \"ICI_YX_dist_pre_norm\", \"stimulus_X_Y\", \"Cumulative Density of Pre-Distance\")\n\ngrid.arrange(p1, ncol=1)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-26-2.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(aov(df_prp_both$ICI_YX_rating_pre_norm ~ df_prp_both$stimulus_type_X_Y))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                               Df Sum Sq Mean Sq F value Pr(>F)\ndf_prp_both$stimulus_type_X_Y   1   0.05 0.04751   0.358   0.55\nResiduals                     313  41.48 0.13254               \n```\n\n\n:::\n:::\n\n\n\n### Normality test\n\nTest for normality using Shapiro-Wilk Test for each index. They seems normal.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(df_prp_both$ICI_YX_rating_pre_norm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  df_prp_both$ICI_YX_rating_pre_norm\nW = 0.97394, p-value = 1.777e-05\n```\n\n\n:::\n\n```{.r .cell-code}\nshapiro.test(df_prp_both$ICI_YX_dist_pre_norm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  df_prp_both$ICI_YX_dist_pre_norm\nW = 0.9726, p-value = 1.056e-05\n```\n\n\n:::\n\n```{.r .cell-code}\nshapiro.test(df_prp_both$ICI_YX_rating_post_norm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  df_prp_both$ICI_YX_rating_post_norm\nW = 0.93783, p-value = 3.192e-10\n```\n\n\n:::\n\n```{.r .cell-code}\nshapiro.test(df_prp_both$ICI_YX_dist_post_norm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tShapiro-Wilk normality test\n\ndata:  df_prp_both$ICI_YX_dist_post_norm\nW = 0.88533, p-value = 1.257e-14\n```\n\n\n:::\n:::\n\n\n\n### Correlations\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_shorted_name <- df_prp_both %>%\n  mutate(rating_pre = ICI_YX_rating_pre_norm,\n         rating_post = ICI_YX_rating_post_norm,\n         distance_pre = ICI_YX_dist_pre_norm,\n         distance_post = ICI_YX_dist_post_norm)\n  \nselected_columns <- df_shorted_name[, c('anxiety', 'stress', 'depression', 'Sex_0', 'age', 'rating_pre', 'rating_post', 'distance_pre', 'distance_post')]\n\ncor_matrix <- cor(selected_columns, use = \"complete.obs\")\ncor_matrix\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  anxiety      stress  depression        Sex_0         age\nanxiety        1.00000000  0.84290961  0.84950350  0.013009678 -0.19038253\nstress         0.84290961  1.00000000  0.85358218  0.077319077 -0.22205455\ndepression     0.84950350  0.85358218  1.00000000  0.083863705 -0.18094134\nSex_0          0.01300968  0.07731908  0.08386371  1.000000000  0.07366257\nage           -0.19038253 -0.22205455 -0.18094134  0.073662574  1.00000000\nrating_pre    -0.07560735 -0.07443259 -0.06005502  0.049078888  0.04878348\nrating_post   -0.03295682 -0.02751596 -0.02375800 -0.004242396 -0.08268928\ndistance_pre  -0.10107376 -0.11389789 -0.09086615  0.072636159  0.04887542\ndistance_post -0.03164209 -0.02601200 -0.02175057 -0.075899821 -0.12185594\n               rating_pre  rating_post distance_pre distance_post\nanxiety       -0.07560735 -0.032956823  -0.10107376   -0.03164209\nstress        -0.07443259 -0.027515956  -0.11389789   -0.02601200\ndepression    -0.06005502 -0.023758000  -0.09086615   -0.02175057\nSex_0          0.04907889 -0.004242396   0.07263616   -0.07589982\nage            0.04878348 -0.082689278   0.04887542   -0.12185594\nrating_pre     1.00000000  0.309718470   0.55006694    0.29041970\nrating_post    0.30971847  1.000000000   0.33540380    0.59092254\ndistance_pre   0.55006694  0.335403797   1.00000000    0.31594470\ndistance_post  0.29041970  0.590922542   0.31594470    1.00000000\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plot the heatmap using corrplot\ncorrplot(cor_matrix, method = \"color\", tl.col = \"black\", tl.srt = 45, \n         addCoef.col = \"black\", number.cex = 0.7, col = colorRampPalette(c(\"blue\", \"white\", \"red\"))(200),\n         title = \"Correlation Heatmap\", mar = c(0, 0, 1, 0))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n\n\n### Assign styles\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate the SD for Pre and define participants' styles\nrating_quantile <- quantile(df_prp_both$ICI_YX_rating_pre_norm, c(1/3, 2/3))\ndist_quantile <- quantile(df_prp_both$ICI_YX_dist_pre_norm, c(1/3, 2/3))\n\ndf_prp_both <- df_prp_both %>%\n  mutate(# rating\n         sd_pre_rating = sd(ICI_YX_rating_pre_norm, na.rm = TRUE),\n         mean_pre_rating = mean(ICI_YX_rating_pre_norm, na.rm = TRUE),\n         style_rating = case_when(\n           #ICI_YX_rating_pre_norm > mean_pre_rating + sd_pre_rating ~ \"Competitive\",\n           #ICI_YX_rating_pre_norm < mean_pre_rating - sd_pre_rating ~ \"Facilitative\",\n           ICI_YX_rating_pre_norm > rating_quantile[2] ~ \"Competitive\",\n           ICI_YX_rating_pre_norm < rating_quantile[1] ~ \"Facilitative\",\n           .default = \"No-Difference\"\n         ),\n         # distance\n         sd_pre_distance = sd(ICI_YX_dist_pre_norm, na.rm = TRUE),\n         mean_pre_distance = mean(ICI_YX_dist_pre_norm, na.rm = TRUE),\n         style_distance = case_when(\n           #ICI_YX_dist_pre_norm > mean_pre_distance + sd_pre_distance ~ \"Competitive\",\n           #ICI_YX_dist_pre_norm < mean_pre_distance - sd_pre_distance ~ \"Facilitative\",\n           ICI_YX_dist_pre_norm > dist_quantile[2] ~ \"Competitive\",\n           ICI_YX_dist_pre_norm < dist_quantile[1] ~ \"Facilitative\",\n           .default = \"No-Difference\"\n         ))\n```\n:::\n\n\n\nHow many participants in each style?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_prp_both %>%\n  group_by(style_rating) %>%\n  summarize(n = n_distinct(subjectID))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 2\n  style_rating      n\n  <chr>         <int>\n1 Competitive     105\n2 Facilitative    105\n3 No-Difference   105\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_prp_both %>%\n  group_by(style_distance) %>%\n  summarize(n = n_distinct(subjectID))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 2\n  style_distance     n\n  <chr>          <int>\n1 Competitive      105\n2 Facilitative     105\n3 No-Difference    105\n```\n\n\n:::\n:::\n\n\n\n## Final Plot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# a function to plot ICI\nplot_ICI <- function(df, pre, post, style, title) {\n  # Classify based on the `pre` column\n  df_style <- df %>%\n    mutate(style = .data[[style]])\n  \n  # df_style <- df_style %>% filter(style != 'No-Difference')\n  \n  # Reshape the data\n  df_melted <- df_style %>%\n    select(all_of(c(pre, post, 'group', 'style'))) %>%\n    pivot_longer(cols = all_of(c(pre, post)), names_to = \"flip\", values_to = \"value\") %>%\n    mutate(flip = recode(flip, !!sym(pre) := \"Pre\", !!sym(post) := \"Post\"))\n  \n  # Order the levels\n  df_melted$flip <- factor(df_melted$flip, levels = c(\"Pre\", \"Post\"))\n\n  # Summarize the data to calculate mean and 68% confidence interval\n  df_summary <- df_melted %>%\n    group_by(group, style, flip) %>%\n    summarize(\n      mean_value = mean(value, na.rm = TRUE),\n      se = sd(value, na.rm = TRUE) / sqrt(n()), \n      ci_68 = se * qnorm(0.84),   # Approx 68% CI (1 standard error)\n      .groups = \"drop\"\n    )\n  \n  # Plot using ggplot2 with error bars\n  g <- ggplot(df_summary, aes(x = flip, y = mean_value, color = group, group = group)) +\n    geom_point(size = 2) +  # Increase point size\n    geom_line(linewidth = 1) +  # Use linewidth for the main lines\n    geom_errorbar(aes(ymin = mean_value - ci_68, ymax = mean_value + ci_68), width = 0.05, linewidth = .8) +  # Error bars with thinner lines\n    facet_wrap(~style, scales = \"fixed\", nrow = 1) +  # Use \"fixed\" for shared y-axis\n    labs(title = title, y = \"ICI\", x = \"\") +\n    theme_minimal() +\n    theme(\n      plot.title = element_text(hjust = 0.5, size = 16, face = \"bold\"),  # Adjust title size\n      axis.title = element_text(size = 14),  # Axis title size\n      axis.text = element_text(size = 12),   # Axis text size\n      strip.text = element_text(size = 14),  # Facet title size\n      legend.position = \"right\",\n      legend.text = element_text(size = 12),  # Adjust legend text size\n      panel.grid.major.x = element_blank(),  # Remove major vertical grid lines\n      panel.grid.minor.x = element_blank(),  # Remove minor vertical grid lines\n      panel.grid.major.y = element_line(color = \"lightgrey\", linewidth = 0.1),  # Add major horizontal grid lines\n      panel.grid.minor.y = element_blank(),  # Remove minor horizontal grid lines\n      panel.spacing = unit(1, \"lines\"),  # Tighten space between panels\n      axis.line.x = element_line(color = \"black\"),  # Add x-axis line\n      axis.line.y.left = element_line(color = \"black\")  # Left y-axis\n    ) +\n    scale_color_manual(values = c(\"blue\", \"orange\")) \n\n  # Display the plot\n  print(g)\n}\n\n# Example usage\nplot_ICI(df_prp_both, 'ICI_YX_rating_pre_norm', 'ICI_YX_rating_post_norm', 'style_rating', 'Normalized ICI-YX Ratings')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-34-1.png){width=1248}\n:::\n\n```{.r .cell-code}\nplot_ICI(df_prp_both, 'ICI_YX_dist_pre_norm', 'ICI_YX_dist_post_norm', 'style_distance', 'Normalized ICI-YX Distances')\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-34-2.png){width=1248}\n:::\n:::\n\n\n## Convert data to a long format\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_prp_long <- df_prp_both %>%\n  select(subjectID, group, style_rating, style_distance, ICI_YX_rating_pre_norm, ICI_YX_rating_post_norm, ICI_YX_dist_pre_norm, ICI_YX_dist_post_norm) %>%\n  pivot_longer(cols = c(ICI_YX_rating_pre_norm, ICI_YX_rating_post_norm, ICI_YX_dist_pre_norm, ICI_YX_dist_post_norm), names_to = \"Index\", values_to = \"value\") \n# save to CSV\nwrite_csv(df_prp_long, \"./exp4-ICI.csv\")\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\n# Discussion\n\n# References\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}